3.7.2 - Network Fundamentals

	Domain Name System (DNS) - port 53
		DNSs translate domain names to IP addresses

		Four diffent types of servers are involved in the system.
			1. DNS Recursor - receives the query from the user and makes any 
				additional requests needed.
			2. Root Nameserver - Servers as a reference to other more specific
				locations. The first step in the resolution.
			3. TLD Nameservers - The Top Level Domain server handles the 
				.com portion.
			4. Authoritative Nameserver - If the first 3 servers passed the 
				correct information, the Authoritative Nameserver will be able
				to find the correct IP address for the domain name originally 
				sent to the DNS Recursor.
	
	
	Simple Mail Transfer Protocal (SMTP) - port 25, 465, 587, 2525, 25025
		The standard mail sending protocal. An application layer protocol.

		SMTP model is of two types:
			1. End-to-end - Used to communicate between different organizations
			2. Store-and-forward - Used within an organization
			
		A client will connect directly to the destinations SMTP server

	
	Internet Control Message Protocal (ICMP) - 
		Used as a support protocal on network devices for sending the error 
			messages and operations information.

	
	Dynamic Host Configuration Protocal (DHCP) - 67 (server), 68 (client)
		An application layer protocal used to provide:
			1. Subnet Mask
			2. Router Address
			3. DNS Address
			4. Vendor Class Identifier

		Based on a client-server model and based on discovery, offer, request, 
			and ACK.

		Uses UDP servcies. IP address is assigned from a pool of addresses.

		The client and server exchange 4 DHCP messages in order to make a 
			connection, also called DORA.
			1. DHCP Discovery Message - Generaged by client to discover if there
				are any DHCP servers present. Broadcast to all devices present 
				in a network to find the DHCP server.
			2. DHCP Offer Message - The server will respond to the client by 
				broadcasting an offer message containing the IP address and 
				any other TCP configuration information the client needs. If 
				there are multiple DHCP servers on the network, the client will 
				accept the first offer message it receives.
			3. DHCP Request Message - When the client receives an offer message, 
				it responds by broadcasting a request message in order to find 
				any other machine on the network with the same IP address. If 
				there are none, the message is received by the server as 
				acceptance of the IP address.
			4. DHCP Acknowledgement Message - Response to the request message 
				confirming the acceptance.
			5. DHCP Negative Acknowledgement Message - Response to the request 
				message when no valid IP address is available.
			6. DHCP Decline - Clinet-to-Server message sent when the client 
				deams the IP configuration invalid.
			7. DHCP Release - Client-to-Server message sent to release the IP 
				configurations back to the pool.
			8. DHCP Inform - Client-to-Server message when the client receives 
				IP informaion manully and needs other configuration parameters.
	
--------------------------------------------------------------------------------

3.1.23 - Terminology associated with multi-threaded programs

	create - Starts a new thread for the multi-threaded processes. pthead 
				uses pthread_create() to create a new thread while the syscall 
				does the same with clone().

	exit - Terminates the thread and does not return to the caller. pthread uses 
			pthread_exit() to terminate a thread while keeping the process 
			alive. The system uses exit() which will also terminate the process 
			even if all threads have not terminated.

--------------------------------------------------------------------------------

3.2.9 - Terms and fundamentals associated with object-oriented programming using 
			Python.

	a. Class - A bundling of data and functionality creating a new type of 
			object, allowing new instances of that object to be made. Where 
			C structs allow a programmer to organize data, Python classes 
			allow a programmer to organize data and operations for using 
			that data.

	b. Object - A collection of properties and methods that act on the data. 
			Objects are created from classes that define their structure.

	c. Difference between an object when discussing a class - A class is the 
			ruling body of an object. An object is how you access the data and 
			methods of a class. Multiple objects can be spawned from any class.

	d. Advantage to object-oriented programming - There are four pillars fo OOP 
			that define its advantage. These pillars work together to reduce 
			complexity, increase reusablitly, isolate impact of change, reduce 
			reducdancy, and simplify case dependant code.
				1. Encapsulation - By grouping properties with methods that 
					act on them we are able to associate methods with their 
					properites and avoid having to link them together reducing 
					the amount of parameters that must be passed between the 
					methods and properties.
				2. Abstraction - This is the practice of reducing the number of 
					methods and properites that are visible outside the class. 
					A similare practice can be done is C by creating static 
					functions, however, this only reduces the functions to the 
					file that it is relavent to, not to only the functions and 
					variables that it applies to. Both properties and methods 
					can be created as private to protect the outside world from 
					having to worry about them. Not only does this simplify the 
					use of the object but it also protects the object from the 
					Impact of Change. Since all the private properties and 
					methods are independent of anything outside the object, 
					making a change to one class will have minor affects on 
					another.
				3. Inheritance - Allows you to inherent, or gain access to, 
					properties and methods from another object, reducing the 
					amount of redundant code requried to do similar tasks.
				4. Polymorphism - Reduces the need to have long switch case 
					statements by allowing a method to behave differently based 
					on its environment.

	e. Inheritance - Allows you to inherent, or gain acces to properties and 
			methods from another object, reducing the amount of redundant code 
			required to do simiar tasks. This definition could have inherented 
			the definition of the 3rd pillar in object d rather than 
			restating it.

	f. The keyword "Super" - Allows the child class to access teh parent's 
			class' init() property. This allows you to build classes that extend 
			the functionality of previously built classes without the need to 
			alter the existing class.

	g. Initialization function of a constructor - The __init__() method of a 
			class, is used to initialize data members of the class when an 
			object of the class is created, giving every object of the class 
			the same "start" point.

	h. The keyword "self" - Represents the instance of the class. "self" can 
			access the attributes and methods of the class. It binds attributes 
			with the given arguments.

	i. The getter and setter functions - Functions specifically designed to 
			retrieve (get) or assign (set) a private property within an object. 
			A way of treating the property as if it were public.

	j. Attributes of a class - Attributes which are owned by the class itself. 
			They are shared among all instances of the class, therefore, 
			maintaining the same value across every instance.

	k. Factory design patterns - A creational pattern that is used for creating 
			an object that will be instantiated at runtime. Used when it is 
			unknown how many or what type of objects will be needed until 
			during runtime.

	l. Singelton design patterns - Only one instance of the class can exist.

	m. Adapter design patterns - Allows two incompatible interfaces to interact 
			via a mediatory that translates what one interface wants and 
			what another is offering.

	n. Bridge design patterns - Allows the programmer to separate the 
			abstraction from the implementation. This allows the abstracion and 
			the implementation to be developed independently. 

--------------------------------------------------------------------------------

3.5.1 - Describe terms and concepts associated with OS virtualization.

	a. Processes - A program in execution, an active entity. A process has its 
			own memory map.

			Attributes/Characteristics:
				1. Process ID - A unique identifier assigned by the OS.
				2. Process state:
						New - New/or currently being created.
						Ready - After creation; ready for execution.
						Run - Currently running in CPU; only one process at a 
							time can be under execution in a single processor.
						Wait (or Block) - When a process requires I/O access.
						Complete (or Terminated) - The process completed its 
							execution.
						Suspended Ready - When the ready que becomes full, some 
							processes are moved to suspended ready are moved to 
							suspended ready state.
						Suspended Block - When waiting que becomes full.
				3. CPU Registers - Like the program counter.
				4. Accounts Information.
				5. I/O status informaion - Devices allocated to the process, 
						open files, etc.
				6. CPU Scheduling Information

			Attributes of a process are call its context. Every process has its 
			own process control block.

			Context Switching: The process of saving the context of one process 
				and loading the context of another. This happens when:
					1. High-Priority process becomes "Ready".
					2. An interrupt occures.
					3. User and kernal mode switch (not always).
					4. Preemtive CPU scheduling used.
				
			Context vs Mode Switching: A mode switch occures when CPU privilege 
				level is changed. e.g. A system call occures or a fault occures. 
				Because the kernal is more privvilaged than a user, if the user 
				is trying to do something that only the kernal can do, a mode 
				switch will occure. A mode switch will occure for a context 
				switch since only the kernal can cause a context switch.

			CPU-bound vs I/O-bound Processes: A CPU-bound process requires more 
				CPU time or spends more time in the running state. An I/O-bound 
				process requires more I/O time and less CPU time, thus spends 
				more time in the wait state.

	b. CPU Scheduling - Scheduling of processes is done to finish the work. 
			Times:
				Arrival Time: Time the process arrives in the ready que. 
				Completion Time: Time the process completes its execution.
				Burst Time: Time required by a process for CPU execution.
				Turn Around Time: Time difference between completion 
					and arrival.
				Wait Time: Time difference between Turn Around Time and 
					Burst Time.
			
			CPU Scheduling allows one process time  on the cpu while another is 
			waiting for I/O.

			Objectives: 
				- Max CPU utilizaition
				- Fair allocation
				- Max throughput
				- Min turn around time
				- Min wait time
				- Min responce time

			Scheduling Algorithms: See Below - 3.5.3.e

	c. Paging Tables - A memory management scheme that eliminates the need for 
			continuous allocation of physical memory.

			Logical / Virtual Address - An address generated by the CPU.
			Logical / Virtual Address Space - Full set of logical addresses 
				generated by a program.
			Physical Address - An address actually available within the 
				memory unit.
			Physical Address Space - Full set of physical addresses 
				corresponding to the logical address.

			Memory Management Unit (MMU) mapes virtual to physical addresses; 
				known as paging technique.

			Physical address space is broken up into Frames.
			Logical address space is broken up into Pages.

			Frame size = Page size

			Page Number (p): The number of bits required to represent the pages 
				in logical address space or frame number.

			Page Offset (d): The number of bits required to represent 
				particular word in a page size of logical address space or 
				page offset.

			Frame Number (f): The number of bits required to reprent the frame 
				of physical address space or frame number.

			Frame Offset (d): Number of bits required to represent particular 
				word in a frame or frame size of physical address space or 
				word number of a frame or frame offset.

			Translation look-aside Buffer (TLB): Small, fast, lookup cache used 
				to store tag and value for each entry.

			Each process gets its own page Tables.

	d. Caching - Extreamly fast memory type used as a buffer between the 
			relativly slow RAM and super fast CPU. Caching reduces the average 
			time to access data from the main memory. Stores copies fo data 
			from frequently used memory locations. Different from the chaches 
			found on the CPU which store instructions and data.

			Levels of memory:
				1. Registers - Stores and accepts data that is immediatly stored 
					in the CPU. Common use: accumulator, program counter, 
					address register.
				2. Cache memory - Fastest memory; tempory storagefor quick 
					access to common data.
				3. Main Memory - Non residual memory; main RAM block.
				4. Secondary Memory - External memory; not fast but non-volital.

	e. Kernal and User-Mode Memory - Kernal mode is reserved for the must 
			trusted applications since it gets raw access to all the hardware 
			componets on the system. Applications running in user mode that need 
			access to kernal mode things must rely on API calls to "ask the 
			kernal to do it"; this includes accessing physical memory. They 
			reason for the separation is for stability. When an application 
			running in user mode crashes, that application crashes and the user 
			can recover from the crash and fix the problem. A common crash in 
			user mode is trying to access memory that is not owned by that 
			process, throwing a segfault. When there is a crash in kernal mode, 
			however, the entire system crashes and there is no recovering; time 
			to turn it off and back on. Looking at this from a memory 
			perspective, the user's application, running in user-mode, has a set
			block of memory that the kernal allocates to it. The application can 
			do just about anything they want with this memory. As discussed 
			before, if the application attempts to access memory that is not 
			allocated to it, the system will throw a segfault and the 
			application will crash. The kernal is the true owner of all memory 
			and is responcible to allocating different blocks to the 
			applications requesting it. The kernal is like the landlord and the 
			user-mode applications are the tenents. Since the user-mode 
			applications are dependant on the API calls to get the kernal to 
			access the memory for them, it can be slow to r/w when compared to 
			the kernal, who just can reachout and grab what it wants. This is 
			why applications that require the fastest accesses are run in 
			kernal mode. A common application that does this are graphic 
			drivers. Windows Vista ran graphics drivers in user mode and users 
			experianced a 10% speed reduction when running games.

--------------------------------------------------------------------------------

3.5.3 - Describe terms and concepts associated with OS Concurrency.

	a. Threading - Threads divid the methods of a process into separate elements 
			that each can be executed by the CPU. They share resources and are 
			quick to spin up and down making them less costly than starting an 
			entire process. Threading allows a complexe problem to be complete 
			in parallel rather than in series. All threads are apart of a single 
			process. The process controls the memory that all threads share. 
			In all threads share: Text segment (memory), Data segment (memory), 
			BSS segment (memory), Open file descriptors, Signals, Current 
			working directory, User and group IDs. They do have their own: 
			Thread ID, Saved registers, Stack pointers, Instruction pointers, 
			Stack (local variables, temporary variables, return addresses), 
			Signal mask, Priority (scheduling information).

	b. Locks - Locks can be applied to resources shared by other threads, 
			preventing anyother thread from reading/writing to the resource. If 
			a thread reaches a lock-point and it is locked, it will hold until 
			the lock is availble, then it will lock it and do what it needs to 
			do.

	c. Race Conditions - An undesirable event that can happen when multiple 
			entities access or modify shared resources in a system. The system 
			behaves correctly when these entities use the shared resource as 
			expected. But sometimes due to uncontrollable delays, the sequence 
			of operations may change due to relative timing of events, when this 
			happens, the system may enter a state not designed for and hence 
			fail. The "race" happens because this type of failure is dependant 
			on which entity gains access to the shared resource first.

	d. Deadlocks - A state in which each member of a group is waiting for 
			another member, including itself, to take action, such as sending a 
			message of more commonly releasing a lock. Deadlocking occures when 
			a process or thread enters a waiting state because a requested 
			system resource is held by another waiting process, which in turn is 
			waiting for another resource held by another waiting process. 
			Fastest way to deadlock: Lock a mutex, and then try to lock 
			it again.

	e. Scheduling modules i.e. round-robin, etc. - Algoritms used to control 
			CPU scheduling.

			First Come First Serve (FCFS): (Non-preemptive) The simplest 
				algorithm. Schedules accourding to arrival times. When a process 
				enters the ready que, its PCB is linked to the tail of the 
				job que.

			Shortest Job First (SJF): (Non-preemptive) The Process with the 
				shortest Burst Time is processed first. FCFS used to break tie.

			Longest Job First (LJF): (Non-preemptive) The priority is given to 
				the process with the longest Burst Time. Once the process begins 
				execution, it cannot be interupted.

			Shortest Remaining Time First (SRTF): (Preemtive) The preemptive 
				mode of SJF; jobs are scheduled according ot shortest 
				remaining time.
			
			Longest Remaining Time First (LRTF): (Preemtive) The preemptive mode 
				of LJF; the priority is given to jobs with the longest Burst 
				time remaining.

			Round Robin Scheduling: A fixed time is set 
				(Time Quantum/Time Slice). If the process completes before time 
				is up, the process releases the CPU as usual and the next job in 
				the que is run. Otherwise, the scheduler throws an interupt, a 
				context switch occures, the process is placed at the tail of 
				the que, and the next process is run.
			
			Priority Based Scheduling: (Non-preemptive) Jobs are processed based 
				on priority. Ties are broken with FCFS. Starvation is possible.

			Highest Responce Ratio Next (first) (HRRN): Avoids starvation. 
				Ratio: (wait time + burst time) / burst time.

			Multilevel Queue Scheduling: Utilizes multiple queues to slot 
				processes of different priorities in different ques. The 
				top-level que is processed to completion and the next que is 
				addressed. Starvation possible.

			Multilevel Feedback Queue Scheduling: Allows processes to be moved 
				between ques. Based on characteristics of the processes CPU 
				burst; if a process uses to much CPU time it is moved to a 
				lower-priority que.

			Completely Fair Scheduler (CFS): Scheduler that the linux Kernal 
				2.6.23+ uses. Created by Ingo Molnor, based on the Rotating 
				Staircase Deadline scheduler (SDS) by Con Kolivas, no 
				heuristics.

				Ideal Fairness: N processes each get (100/N)% of CPU time.

				Each process gets a virtual runtime input in its PCB. For every 
				scheduling point if a process has run for t ms its vruntime is 
				increased by t.

				When a context switch is instigated, the process with the 
				lowest vruntime is selected for execution.

				The processes are stored in a red-black tree with the lowest 
				vruntime process at the far left, therefore, the next process to 
				be executed will be both the process with the lowest vruntime 
				and the process furthest left in the tree. NOTE: Context switch 
				only occures if there is another process with a small vruntime 
				than the current process.

				Complexity:
					The left most node is cached in min_vruntime making the 
					context switch O(1).

					Inserting the currently running process back into the tree 
					requires o(log(n)).

					Tasks move from left to right after execution avoiding 
					starvation. This is because vruntime is not a function of 
					how long it wil take to complete the task but rather how 
					much time the task has spent running.

					Why Red-Black Tree? Its self-balancing making all operations 
					O(log(n)).

				CFS weights vruntimes to prioritize processes, known as the 
				processes niceness. This is done by either accelerating or 
				slowing the vruntime: vruntime += t * niceness.

--------------------------------------------------------------------------------

3.5.5 - Describe terms and concepts associated with OS Persistence.

	a. Von Nuemann architecture - Published by John von Nuemann in 1945.
			This design is still widely used in computers today. It consistes of
			a Control Unit, Arithmetic and Logic Unit (ALU), Memory Unit, 
			Registers, and I/O. The insertruction data and program data are 
			stored in the same memory.

			CPU - Contains the ALU and CU as well as a variety of registers.

			Registers - High speed areas of the CPU, all data is stored in a 
				register in order for the CPU to use it.

				MAR - Memory Address Register - Holds the memory location of 
					data that needs to be accessed.
				MDR - Memory Data Register - Holds data that is being 
					transferred to or from memory.
				AC - Accumulator - Where intermediate arithmetic and logic 
					results are stored.
				PC - Program Counter - Contains the address of the next 
					instruction to be executed.
				CIR - Current Instruction Register - Contains the current
					instruction during processing.

			Arithmetic and Logic Unit (ALU) - Performs the arithmetic (add, 
				subtract, etc) and logical (AND, OR, NOT, etc) operations.

			Control Unit (CU) - Controls the operations of the compute's ALU, 
				memory, and I/O. Also provides the timing and control 
				signals.

			Buses - The paths that connect all the parts of the computer. 

				Address Bus - Carries the addresses of data (but not the data) 
					between the processor and the memory.
				
				Data Bus - Carries data between the processor, the memory unit
					and the I/O devices.
				
				Contorl Bus - Carries control signals/commands from the CPU 
					(and status signals from other devices) in order to 
					control and coordinate all the activities within 
					the computer.

			Memory Unit - RAM. There is also secondary memory (HHD/SSD) that are 
				slow to access.

	b. Harvard architecture - Separates storage and signal pathways for 
			instructions and data. This contrast the Von Nuemann architecture 
			where these run on the same pathway. Modified Harvard architecture 
			is commonly used today, where the system appears to operate strictly 
			in a Von Nuemann architecture, however, the CPU separates the 
			instructions from the data in separate caches. By separatign them, 
			you get a dedicated pathway for each, although it is not strictly 
			speaking a Harvard architecture. This modified method allows the 
			system to store instructions and data in the same address in RAM 
			causing them to be cached through the same pathway, but once cached 
			in the separate cached spaces, the two types of data will have 
			independent pathways. This creates a system the acts as a Von 
			Nuemann system outside the CPU and a Harvard system within the CPU.

	c. File systems - The logical storage of persistent data that is typically 
			stored in a tree structure on either a Hard Drive Disk or Solid 
			State Disk. File Systems must be mounted to a system before they can 
			be accessed by the system.

	d. The boot process - 
			
			BIOS - Basic I/O System - executes MBR
				Performs some systems integrity checks.
				Searches, loads, and executes the boot loader program.
				Once the boot loader is detected and loaded into memory, BIOS 
					gives the controls to it.

			MBR - Master Boot Record - executes GRUB
				Located in the 1st sector of the bootable disk. Typically 
					/dev/hda, or /dev/sda. Less than 512 bytes and has 3 
					components: Primary boot loader (first 446 bytes), 
					Partition table info (next 64 bytes), and MBR validation 
					check (last 2 bytes). Also contains information about GRUB 
					(or LILO). 

			GRUB - Grand Unified Bootloader - executes Kernal
				If there are multiple kernel images installed on the system, you 
					can chose which one to execute. 

			Kernal - Kernal - executes /sbin/init
				Mounts the root file system as specified in the "root=" in 
					grub.conf. Executes the /sbin/init program. initrd 
					(Initial RAM Disk) is used as a temporary file system until 
					the real root system is mounted. 

			Init - Init - executes runlevel programs
				Looks at /etc/inittab to decide the linux run level.
					Levels:
						0 - Halt
						1 - Single user mode
						2 - Multiuser, without NFS
						3 - Full multiuser mode
						4 - unused
						5 - X11 (normal)
						6 - reboot

			Runlevel - Runlevel programs are executed from /etc/rc.d/rc*.d/
				In the rc*.d directory there are programs that start with S 
					and K. S programs are used during startup. K programs are 
					used during shutdown; K for Kill. The number following these 
					S's and K's are the sequence number denoting the order they 
					should be executed. 
